import time
import pandas as pd
import os
import json
import requests
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# Cáº¥u hÃ¬nh
BASE_URL = "https://wichart.vn/vi-mo/vn"
OUTPUT_DIR = "scrapers/wichart/data"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "wichart_indicators_hybrid.csv")

TARGET_CATEGORIES = [
    "Tá»•ng sáº£n pháº©m quá»‘c ná»™i",
    "Sáº£n xuáº¥t vÃ  Dá»‹ch vá»¥",
    "TiÃªu dÃ¹ng",
    "GiÃ¡ cáº£",
    "Thá»‹ trÆ°á»ng hÃ ng hoÃ¡",
    "Giao dá»‹ch quá»‘c táº¿",
    "Äáº§u tÆ°",
    "Há»‡ thá»‘ng ngÃ¢n hÃ ng",
    "Thá»‹ trÆ°á»ng tiá»n tá»‡",
    "Thá»‹ trÆ°á»ng vá»‘n",
    "TÃ i khÃ³a",
    "Báº¥t Ä‘á»™ng sáº£n",
    "Thá»‹ trÆ°á»ng lao Ä‘á»™ng"
]

def setup_driver():
    options = Options()
    # KÃ­ch hoáº¡t Performance Logging Ä‘á»ƒ báº¯t URL API
    options.set_capability("goog:loggingPrefs", {"performance": "ALL"})
    
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    # TÃ¬m browser path (Brave/Chrome/Edge)
    possible_paths = [
        "/Applications/Brave Browser.app/Contents/MacOS/Brave Browser",
        "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome",
        "/Applications/Microsoft Edge.app/Contents/MacOS/Microsoft Edge",
        "/Applications/CocCoc.app/Contents/MacOS/CocCoc", 
    ]
    binary_path = next((p for p in possible_paths if os.path.exists(p)), None)
    if binary_path:
        print(f"â„¹ï¸Sá»­ dá»¥ng Binary: {binary_path}")
        options.binary_location = binary_path

    return webdriver.Chrome(options=options)

def get_api_url_from_logs(driver):
    """QuÃ©t log performance Ä‘á»ƒ tÃ¬m URL API JSON"""
    logs = driver.get_log("performance")
    candidates = []
    for entry in logs:
        try:
            message = json.loads(entry["message"])["message"]
            if message["method"] == "Network.responseReceived":
                url = message["params"]["response"]["url"]
                # Lá»c URL tiá»m nÄƒng
                if "wichart.vn" in url and ("api" in url or "data" in url or "getByCategoryID" in url):
                    candidates.append(url)
        except:
            pass
    return candidates

def scrape_wichart_hybrid():
    print(f"ðŸš€ Báº¯t Ä‘áº§u Scraper (Hybrid Selenium + Requests)...")
    driver = setup_driver()
    collected_data = []

    try:
        print("â³ Äang táº£i trang...")
        driver.get(BASE_URL)
        time.sleep(5) # Äá»£i init

        # Láº¥y session cookies vÃ  Headers chuáº©n
        selenium_cookies = driver.get_cookies()
        session = requests.Session()
        for cookie in selenium_cookies:
            session.cookies.set(cookie['name'], cookie['value'])
        
        session.headers.update({
            "User-Agent": driver.execute_script("return navigator.userAgent"),
            "Referer": "https://wichart.vn/",
            "Origin": "https://wichart.vn",
            "Accept": "application/json, text/plain, */*",
        })

        for category in TARGET_CATEGORIES:
            print(f"\nðŸ” Äang xá»­ lÃ½ nhÃ³m: {category}")
            
            try:
                # XÃ³a log cÅ©
                driver.get_log("performance")
                
                # Logic Click cáº£i tiáº¿n
                driver.execute_script("window.scrollBy(0, 200);")
                time.sleep(0.5)

                xpath = f"//*[text()='{category}'] | //*[contains(text(), '{category}')]"
                elements = driver.find_elements(By.XPATH, xpath)
                
                # Retry Scroll náº¿u khÃ´ng tháº¥y
                if not elements:
                    print("   ...KhÃ´ng tháº¥y ngay, thá»­ scroll sÃ¢u hÆ¡n...")
                    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    time.sleep(1)
                    elements = driver.find_elements(By.XPATH, xpath)

                clicked = False
                for el in elements:
                    if len(el.text) > len(category) * 4: 
                        continue
                    
                    if el.is_displayed():
                        try:
                            driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", el)
                            time.sleep(0.5)
                            el.click()
                            clicked = True
                            print(f"   ðŸ–±ï¸ Click: {category}")
                            break
                        except:
                            try:
                                driver.execute_script("arguments[0].click();", el)
                                clicked = True
                                break
                            except:
                                continue
                
                if not clicked:
                    print(f"âŒ KhÃ´ng click Ä‘Æ°á»£c menu {category}")
                    continue

                # Wait logic: Chá» API xuáº¥t hiá»‡n trong log
                print("   â³ Äang chá» API response...")
                api_url = None
                time.sleep(2) 
                
                # QuÃ©t log tÃ¬m API chuáº©n
                candidate_urls = get_api_url_from_logs(driver)
                
                # Logic chá»n URL thÃ´ng minh
                for url in reversed(candidate_urls): # Láº¥y má»›i nháº¥t trÆ°á»›c
                    if "getByCategoryID" in url:
                        api_url = url
                        break
                
                if not api_url and candidate_urls:
                    # Fallback láº¥y URL cÃ³ váº» giá»‘ng API nháº¥t
                    for url in reversed(candidate_urls):
                        if "wichartapi" in url:
                            api_url = url
                            break

                success_api = False
                if api_url:
                    print(f"   ðŸ”— Báº¯t Ä‘Æ°á»£c API URL: {api_url}")
                    
                    try:
                        resp = session.get(api_url, timeout=10)
                        if resp.status_code == 200:
                            data = resp.json()
                            items = []
                            if isinstance(data, list): items = data
                            elif isinstance(data, dict):
                                for k in ['data', 'result', 'items', 'rows']:
                                    if k in data and isinstance(data[k], list):
                                        items = data[k]
                                        break
                                if not items: items = [data]

                            count = 0
                            for item in items:
                                name = item.get('nameVi') or item.get('name') or item.get('indicatorName')
                                code = item.get('code') or item.get('indicatorCode')
                                unit = item.get('unit')
                                
                                if name:
                                    collected_data.append({
                                        "Category": category,
                                        "Indicator": name,
                                        "Code": code,
                                        "Unit": unit,
                                        "Type": "API_EXTRACTED"
                                    })
                                    count += 1
                            
                            if count > 0:
                                print(f"   âœ… Láº¥y Ä‘Æ°á»£c {count} chá»‰ sá»‘ tá»« API.")
                                success_api = True
                            else:
                                print("   âš ï¸ API tráº£ vá» data rá»—ng hoáº·c khÃ´ng Ä‘Ãºng cáº¥u trÃºc.")
                        else:
                            print(f"   âš ï¸ API request lá»—i: {resp.status_code}")
                    except Exception as req_err:
                        print(f"   âš ï¸ Lá»—i request API: {req_err}")
                
                if not success_api:
                    print("   ðŸ”„ Fallback: DÃ¹ng DOM Scraping...")
                    # DOM FALLBACK
                    indicators = driver.execute_script('''
                        const items = [];
                        const allElements = document.querySelectorAll('div, span, p, td, li, a');
                        allElements.forEach(el => {
                            const rect = el.getBoundingClientRect();
                            const text = el.innerText ? el.innerText.trim() : "";
                            if (rect.left > 250 && rect.width > 0 && rect.height > 0 && text.length > 3 && text.length < 150) {
                                items.push(text);
                            }
                        });
                        return [...new Set(items)];
                    ''')
                    
                    count_dom = 0
                    for ind in indicators:
                        bad_keywords = ["bÃ¡o cÃ¡o", "biá»ƒu Ä‘á»“", "xuáº¥t excel", "chia sáº»", "Ä‘Æ¡n vá»‹", "nguá»“n", "dá»¯ liá»‡u", "Ä‘ang cáº­p nháº­t", "wichart", "liÃªn há»‡", "vá» chÃºng tÃ´i", "báº£n quyá»n", "mÃ£ chá»©ng khoÃ¡n", "Ä‘Äƒng nháº­p", "Ä‘Äƒng kÃ½"]
                        if ind.lower() == category.lower(): continue
                        if any(k in ind.lower() for k in bad_keywords): continue
                        if ind.replace('.', '').replace(',', '').replace('/', '').replace('-', '').strip().isdigit(): continue
                        if len(ind) < 4 or ind in ["GiÃ¡ trá»‹", "Thay Ä‘á»•i", "NgÃ y cáº­p nháº­t", "TÃªn chá»‰ sá»‘"]:
                            continue

                        collected_data.append({
                            "Category": category,
                            "Indicator": ind,
                            "Code": "DOM",
                            "Unit": "",
                            "Type": "DOM_FALLBACK"
                        })
                        count_dom += 1
                    print(f"   âœ… Láº¥y Ä‘Æ°á»£c {count_dom} chá»‰ sá»‘ tá»« DOM.")

            except Exception as e:
                print(f"âŒ Lá»—i: {e}")

    except Exception as main_err:
        print(f"âŒ Lá»—i fatal: {main_err}")
    finally:
        driver.quit()

    if collected_data:
        df = pd.DataFrame(collected_data)
        df.drop_duplicates(subset=['Category', 'Indicator'], inplace=True)
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        df.to_csv(OUTPUT_FILE, index=False, encoding="utf-8-sig")
        print(f"\nðŸŽ‰ HoÃ n táº¥t! ÄÃ£ lÆ°u {len(df)} dÃ²ng vÃ o {OUTPUT_FILE}")

if __name__ == "__main__":
    scrape_wichart_hybrid()